{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âœˆï¸ Bangladesh Flight Fare Prediction\n",
    "## Complete EDA, Modelling & Insights Notebook\n",
    "\n",
    "**Author**: Carl Nyameakyere Crankson  \n",
    "**Dataset**: [Kaggle - Flight Price Dataset of Bangladesh](https://www.kaggle.com/datasets/mahatiratusher/flight-price-dataset-of-bangladesh)  \n",
    "**Goal**: Predict total flight fares using airline, route, class, and seasonal features.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Notebook Structure\n",
    "1. **Problem Definition** - Business context & ML task framing\n",
    "2. **Data Loading & Understanding** - Initial inspection\n",
    "3. **Data Cleaning & Preprocessing** - Handle nulls, types, outliers\n",
    "4. **Feature Engineering** - New features, encoding, scaling\n",
    "5. **Exploratory Data Analysis (EDA)** - Full visual analysis\n",
    "6. **Baseline Model** - Linear Regression\n",
    "7. **Advanced Models** - Ridge, Lasso, Decision Tree, Random Forest, Gradient Boost\n",
    "8. **Model Comparison** - Cross-validation & evaluation\n",
    "9. **Model Interpretation** - Feature importance & SHAP-style analysis\n",
    "10. **Insights & Recommendations** - Business findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âš™ï¸ Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed\n",
    "# !pip install pandas numpy matplotlib seaborn scikit-learn xgboost lightgbm jupyter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "\n",
    "# Plotting style\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_theme(style='whitegrid', palette='husl')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "print('âœ… All imports successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Problem Definition\n",
    "\n",
    "### Business Context\n",
    "Airlines and travel platforms need to estimate ticket prices accurately for:\n",
    "- **Dynamic pricing strategies** â€” adjust fares in real-time\n",
    "- **Customer recommendations** â€” suggest best booking times\n",
    "- **Revenue management** â€” forecast revenue by route and season\n",
    "\n",
    "### ML Task Definition\n",
    "| Attribute | Value |\n",
    "|-----------|-------|\n",
    "| **Type** | Supervised Regression |\n",
    "| **Target Variable** | `total_fare_bdt` (Total Fare in BDT) |\n",
    "| **Features** | Airline, Source, Destination, Class, Seasonality |\n",
    "| **Evaluation** | RÂ², MAE, RMSE |\n",
    "\n",
    "### Key Questions to Answer\n",
    "1. Which airline charges the most? The least?\n",
    "2. What are the most expensive routes?\n",
    "3. How much does peak season affect prices?\n",
    "4. Does travel class significantly influence fare?\n",
    "5. What features most strongly predict fare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading & Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset - update path if needed\n",
    "DATA_PATH = '../data/Flight_Price_Dataset_of_Bangladesh.csv'\n",
    "\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "print(f'ğŸ“Š Dataset Shape: {df_raw.shape[0]:,} rows Ã— {df_raw.shape[1]} columns')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and nulls\n",
    "print('=== Data Types & Missing Values ===')\n",
    "info_df = pd.DataFrame({\n",
    "    'dtype': df_raw.dtypes,\n",
    "    'null_count': df_raw.isnull().sum(),\n",
    "    'null_%': (df_raw.isnull().sum() / len(df_raw) * 100).round(2),\n",
    "    'unique_values': df_raw.nunique()\n",
    "})\n",
    "print(info_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print('=== Descriptive Statistics ===')\n",
    "df_raw.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique values for categorical columns\n",
    "cat_cols = df_raw.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    print(f'\\n{col} ({df_raw[col].nunique()} unique):')\n",
    "    print(df_raw[col].value_counts().head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# â”€â”€ 3.1 Rename columns to snake_case â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(' ', '_')\n",
    "    .str.replace('&', 'and')\n",
    ")\n",
    "print('Columns after rename:')\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 3.2 Drop irrelevant columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "drop_cols = [c for c in df.columns if 'unnamed' in c.lower() or 'index' == c.lower()]\n",
    "if drop_cols:\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "    print(f'Dropped: {drop_cols}')\n",
    "\n",
    "print(f'Shape after cleanup: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 3.3 Identify key columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Adjust these to match your actual column names\n",
    "print('Current columns:', df.columns.tolist())\n",
    "\n",
    "# Map to standard names used throughout notebook\n",
    "# Common name variations from this dataset:\n",
    "rename_map = {}\n",
    "\n",
    "# Try to find fare column\n",
    "for col in df.columns:\n",
    "    if 'total' in col and 'fare' in col: rename_map[col] = 'total_fare_bdt'\n",
    "    elif 'base' in col and 'fare' in col: rename_map[col] = 'base_fare'\n",
    "    elif 'tax' in col: rename_map[col] = 'tax_surcharge'\n",
    "    elif col in ['airline', 'airlines']: rename_map[col] = 'airline'\n",
    "    elif 'source' in col and 'code' not in col: rename_map[col] = 'source_city'\n",
    "    elif 'destination' in col and 'code' not in col: rename_map[col] = 'destination_city'\n",
    "    elif 'class' in col: rename_map[col] = 'travel_class'\n",
    "    elif 'season' in col and 'peak' not in col: rename_map[col] = 'seasonality'\n",
    "\n",
    "df.rename(columns=rename_map, inplace=True)\n",
    "print('\\nAfter renaming:', df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 3.4 Fix data types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fare_cols = ['total_fare_bdt', 'base_fare', 'tax_surcharge']\n",
    "for col in fare_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "print('Fare column dtypes:')\n",
    "for col in fare_cols:\n",
    "    if col in df.columns:\n",
    "        print(f'  {col}: {df[col].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 3.5 Handle invalid entries â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "before = len(df)\n",
    "\n",
    "# Remove negative or zero fares\n",
    "if 'total_fare_bdt' in df.columns:\n",
    "    df = df[df['total_fare_bdt'] > 0]\n",
    "    print(f'Removed {before - len(df)} records with non-positive fares')\n",
    "\n",
    "# Handle missing values\n",
    "print(f'\\nMissing values before cleanup:')\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "\n",
    "# Fill numeric with median\n",
    "num_cols = df.select_dtypes(include=np.number).columns\n",
    "for col in num_cols:\n",
    "    if df[col].isnull().any():\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Fill categorical with mode\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "for col in cat_cols:\n",
    "    if df[col].isnull().any():\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "print(f'\\nMissing values after cleanup: {df.isnull().sum().sum()}')\n",
    "print(f'Final shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 3.6 Normalise text fields â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "str_cols = df.select_dtypes(include='object').columns\n",
    "for col in str_cols:\n",
    "    df[col] = df[col].str.strip().str.title()\n",
    "\n",
    "print('Sample after normalisation:')\n",
    "df[str_cols].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 3.7 Outlier detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if 'total_fare_bdt' in df.columns:\n",
    "    Q1 = df['total_fare_bdt'].quantile(0.25)\n",
    "    Q3 = df['total_fare_bdt'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 3 * IQR\n",
    "    upper = Q3 + 3 * IQR\n",
    "\n",
    "    outliers = df[(df['total_fare_bdt'] < lower) | (df['total_fare_bdt'] > upper)]\n",
    "    print(f'Outliers detected (3Ã—IQR rule): {len(outliers):,} ({len(outliers)/len(df)*100:.2f}%)')\n",
    "    print(f'Fare range (3Ã—IQR): {lower:,.0f} â€“ {upper:,.0f} BDT')\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    axes[0].boxplot(df['total_fare_bdt'].dropna(), vert=True, patch_artist=True,\n",
    "                    boxprops=dict(facecolor='steelblue', alpha=0.7))\n",
    "    axes[0].set_title('Fare Distribution (Box Plot)')\n",
    "    axes[0].set_ylabel('Total Fare (BDT)')\n",
    "    axes[0].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "\n",
    "    axes[1].hist(df['total_fare_bdt'], bins=50, color='steelblue', alpha=0.7, edgecolor='white')\n",
    "    axes[1].axvline(df['total_fare_bdt'].mean(), color='red', linestyle='--', label=f\"Mean: {df['total_fare_bdt'].mean():,.0f}\")\n",
    "    axes[1].axvline(df['total_fare_bdt'].median(), color='orange', linestyle='--', label=f\"Median: {df['total_fare_bdt'].median():,.0f}\")\n",
    "    axes[1].set_title('Total Fare Distribution')\n",
    "    axes[1].set_xlabel('Total Fare (BDT)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.suptitle('Fare Outlier Analysis', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('fare_outlier_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 4.1 Derived features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Route\n",
    "if 'source_city' in df.columns and 'destination_city' in df.columns:\n",
    "    df['route'] = df['source_city'] + ' â†’ ' + df['destination_city']\n",
    "elif 'source_code' in df.columns and 'destination_code' in df.columns:\n",
    "    df['route'] = df['source_code'] + ' â†’ ' + df['destination_code']\n",
    "\n",
    "# Route type (domestic / international)\n",
    "domestic_codes = ['DAC', 'CGP', 'CXB', 'ZYL', 'JSR', 'RJH', 'SPD', 'BZL']\n",
    "if 'source_code' in df.columns and 'destination_code' in df.columns:\n",
    "    df['route_type'] = np.where(\n",
    "        df['source_code'].isin(domestic_codes) & df['destination_code'].isin(domestic_codes),\n",
    "        'Domestic', 'International'\n",
    "    )\n",
    "\n",
    "# Peak season flag\n",
    "if 'seasonality' in df.columns and 'is_peak_season' not in df.columns:\n",
    "    peak_keywords = ['peak', 'eid', 'hajj', 'holiday', 'festival', 'winter']\n",
    "    df['is_peak_season'] = df['seasonality'].str.lower().apply(\n",
    "        lambda x: any(k in x for k in peak_keywords)\n",
    "    ).astype(int)\n",
    "\n",
    "# Total fare from components if missing\n",
    "if 'total_fare_bdt' not in df.columns:\n",
    "    if 'base_fare' in df.columns and 'tax_surcharge' in df.columns:\n",
    "        df['total_fare_bdt'] = df['base_fare'] + df['tax_surcharge']\n",
    "\n",
    "# Fare category (binned)\n",
    "if 'total_fare_bdt' in df.columns:\n",
    "    df['fare_category'] = pd.cut(\n",
    "        df['total_fare_bdt'],\n",
    "        bins=[0, 10000, 30000, 60000, 100000, float('inf')],\n",
    "        labels=['Budget (<10K)', 'Economy (10-30K)', 'Standard (30-60K)',\n",
    "                'Premium (60-100K)', 'Luxury (>100K)']\n",
    "    )\n",
    "\n",
    "print(f'Shape after feature engineering: {df.shape}')\n",
    "print(f'New columns: route, route_type, is_peak_season, fare_category')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 4.2 Encode for modelling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_model = df.copy()\n",
    "\n",
    "# Identify ML feature columns\n",
    "feature_cols = []\n",
    "possible_features = ['airline', 'source_code', 'destination_code', 'travel_class',\n",
    "                     'seasonality', 'is_peak_season', 'route_type']\n",
    "\n",
    "for col in possible_features:\n",
    "    if col in df_model.columns:\n",
    "        feature_cols.append(col)\n",
    "\n",
    "target_col = 'total_fare_bdt'\n",
    "print(f'Feature columns: {feature_cols}')\n",
    "print(f'Target: {target_col}')\n",
    "\n",
    "# Label encode categoricals\n",
    "label_encoders = {}\n",
    "for col in feature_cols:\n",
    "    if df_model[col].dtype == 'object' or str(df_model[col].dtype) == 'category':\n",
    "        le = LabelEncoder()\n",
    "        df_model[f'{col}_encoded'] = le.fit_transform(df_model[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Final feature set (encoded)\n",
    "encoded_features = [f'{c}_encoded' if c in label_encoders else c for c in feature_cols]\n",
    "encoded_features = [c for c in encoded_features if c in df_model.columns]\n",
    "\n",
    "print(f'\\nEncoded features: {encoded_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 4.3 Train-test split â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "X = df_model[encoded_features]\n",
    "y = df_model[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'Training set: {X_train.shape[0]:,} samples')\n",
    "print(f'Test set:     {X_test.shape[0]:,} samples')\n",
    "print(f'Features:     {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Exploratory Data Analysis (EDA)\n",
    "### 5.1 Fare Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Total fare histogram\n",
    "axes[0].hist(df['total_fare_bdt'], bins=60, color='steelblue', alpha=0.8, edgecolor='white')\n",
    "axes[0].axvline(df['total_fare_bdt'].mean(), color='red', linewidth=2, linestyle='--',\n",
    "                label=f\"Mean: {df['total_fare_bdt'].mean():,.0f} BDT\")\n",
    "axes[0].set_title('Total Fare Distribution', fontweight='bold')\n",
    "axes[0].set_xlabel('Total Fare (BDT)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].legend()\n",
    "\n",
    "# Fare category breakdown\n",
    "if 'fare_category' in df.columns:\n",
    "    fare_cat_counts = df['fare_category'].value_counts()\n",
    "    colors = ['#2ecc71', '#3498db', '#9b59b6', '#e67e22', '#e74c3c']\n",
    "    axes[1].bar(range(len(fare_cat_counts)), fare_cat_counts.values, color=colors[:len(fare_cat_counts)], alpha=0.8)\n",
    "    axes[1].set_xticks(range(len(fare_cat_counts)))\n",
    "    axes[1].set_xticklabels(fare_cat_counts.index, rotation=30, ha='right')\n",
    "    axes[1].set_title('Fare Category Breakdown', fontweight='bold')\n",
    "    axes[1].set_ylabel('Count')\n",
    "\n",
    "# Base fare vs tax (if available)\n",
    "if 'base_fare' in df.columns and 'tax_surcharge' in df.columns:\n",
    "    axes[2].scatter(df['base_fare'], df['total_fare_bdt'], alpha=0.2,\n",
    "                   color='steelblue', s=5)\n",
    "    axes[2].set_title('Base Fare vs Total Fare', fontweight='bold')\n",
    "    axes[2].set_xlabel('Base Fare (BDT)')\n",
    "    axes[2].set_ylabel('Total Fare (BDT)')\n",
    "else:\n",
    "    axes[2].text(0.5, 0.5, 'Base Fare\\nNot Available\\nin Dataset',\n",
    "                ha='center', va='center', transform=axes[2].transAxes,\n",
    "                fontsize=14, color='gray')\n",
    "    axes[2].set_title('Base Fare vs Total Fare', fontweight='bold')\n",
    "\n",
    "plt.suptitle('Fare Distribution Overview', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('fare_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nğŸ“Š Fare Summary Statistics:')\n",
    "print(df['total_fare_bdt'].describe().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Average Fare by Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'airline' in df.columns:\n",
    "    airline_stats = df.groupby('airline')['total_fare_bdt'].agg(\n",
    "        avg_fare='mean',\n",
    "        median_fare='median',\n",
    "        min_fare='min',\n",
    "        max_fare='max',\n",
    "        booking_count='count'\n",
    "    ).sort_values('avg_fare', ascending=False)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "    # Average fare bar chart\n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.2, 0.8, len(airline_stats)))\n",
    "    bars = axes[0].barh(airline_stats.index, airline_stats['avg_fare'],\n",
    "                        color=colors, alpha=0.85, edgecolor='white')\n",
    "    axes[0].set_xlabel('Average Total Fare (BDT)')\n",
    "    axes[0].set_title('Average Fare by Airline', fontweight='bold')\n",
    "    for bar, val in zip(bars, airline_stats['avg_fare']):\n",
    "        axes[0].text(bar.get_width() + 200, bar.get_y() + bar.get_height()/2,\n",
    "                    f'{val:,.0f}', va='center', fontsize=9)\n",
    "    axes[0].xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "\n",
    "    # Booking count\n",
    "    axes[1].barh(airline_stats.index, airline_stats['booking_count'],\n",
    "                 color='steelblue', alpha=0.75, edgecolor='white')\n",
    "    axes[1].set_xlabel('Number of Bookings')\n",
    "    axes[1].set_title('Booking Count by Airline', fontweight='bold')\n",
    "    axes[1].xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "\n",
    "    plt.suptitle('Airline Analysis', fontsize=15, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('airline_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print('\\nğŸ“Š Airline Fare Statistics:')\n",
    "    print(airline_stats.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare variation by airline (boxplot)\n",
    "if 'airline' in df.columns:\n",
    "    airline_order = df.groupby('airline')['total_fare_bdt'].median().sort_values(ascending=False).index\n",
    "\n",
    "    plt.figure(figsize=(16, 7))\n",
    "    df_plot = df[df['airline'].isin(airline_order)]\n",
    "    sns.boxplot(data=df_plot, x='airline', y='total_fare_bdt',\n",
    "                order=airline_order, palette='husl', fliersize=2)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.title('Fare Variation Across Airlines', fontsize=15, fontweight='bold')\n",
    "    plt.xlabel('Airline')\n",
    "    plt.ylabel('Total Fare (BDT)')\n",
    "    plt.gca().yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('airline_fare_boxplot.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Route Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'route' in df.columns:\n",
    "    route_stats = df.groupby('route')['total_fare_bdt'].agg(\n",
    "        avg_fare='mean',\n",
    "        booking_count='count'\n",
    "    ).sort_values('avg_fare', ascending=False)\n",
    "\n",
    "    top_expensive = route_stats.head(10)\n",
    "    top_popular = route_stats.sort_values('booking_count', ascending=False).head(10)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "    # Top 10 most expensive routes\n",
    "    colors_exp = plt.cm.Reds(np.linspace(0.4, 0.9, 10))\n",
    "    axes[0].barh(top_expensive.index[::-1], top_expensive['avg_fare'][::-1],\n",
    "                color=colors_exp, alpha=0.85, edgecolor='white')\n",
    "    axes[0].set_xlabel('Average Fare (BDT)')\n",
    "    axes[0].set_title('Top 10 Most Expensive Routes', fontweight='bold')\n",
    "    axes[0].xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "\n",
    "    # Top 10 most popular routes\n",
    "    colors_pop = plt.cm.Blues(np.linspace(0.4, 0.9, 10))\n",
    "    axes[1].barh(top_popular.index[::-1], top_popular['booking_count'][::-1],\n",
    "                color=colors_pop, alpha=0.85, edgecolor='white')\n",
    "    axes[1].set_xlabel('Number of Bookings')\n",
    "    axes[1].set_title('Top 10 Most Popular Routes', fontweight='bold')\n",
    "    axes[1].xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "\n",
    "    plt.suptitle('Route Analysis', fontsize=15, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('route_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print('\\nğŸ“ Top 5 Most Expensive Routes:')\n",
    "    print(top_expensive.head().to_string())\n",
    "    print('\\nğŸ“ Top 5 Most Popular Routes:')\n",
    "    print(top_popular.head().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Seasonal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'seasonality' in df.columns:\n",
    "    season_stats = df.groupby('seasonality')['total_fare_bdt'].agg(\n",
    "        avg_fare='mean',\n",
    "        median_fare='median',\n",
    "        booking_count='count'\n",
    "    ).sort_values('avg_fare', ascending=False)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    # Average fare by season\n",
    "    colors_s = ['#e74c3c' if 'eid' in s.lower() or 'peak' in s.lower() else '#3498db'\n",
    "                for s in season_stats.index]\n",
    "    axes[0].bar(season_stats.index, season_stats['avg_fare'],\n",
    "               color=colors_s, alpha=0.85, edgecolor='white')\n",
    "    axes[0].set_title('Average Fare by Season', fontweight='bold')\n",
    "    axes[0].set_ylabel('Average Fare (BDT)')\n",
    "    axes[0].set_xlabel('Season')\n",
    "    axes[0].tick_params(axis='x', rotation=30)\n",
    "    axes[0].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "    for i, (idx, row) in enumerate(season_stats.iterrows()):\n",
    "        axes[0].text(i, row['avg_fare'] + 200, f\"{row['avg_fare']:,.0f}\",\n",
    "                    ha='center', fontsize=9)\n",
    "\n",
    "    # Seasonal boxplot\n",
    "    sns.boxplot(data=df, x='seasonality', y='total_fare_bdt',\n",
    "               order=season_stats.index, ax=axes[1],\n",
    "               palette='Set2', fliersize=2)\n",
    "    axes[1].set_title('Fare Distribution by Season', fontweight='bold')\n",
    "    axes[1].set_ylabel('Total Fare (BDT)')\n",
    "    axes[1].set_xlabel('Season')\n",
    "    axes[1].tick_params(axis='x', rotation=30)\n",
    "    axes[1].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "\n",
    "    plt.suptitle('Seasonal Fare Analysis', fontsize=15, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('seasonal_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print('\\nğŸ“… Seasonal Stats:')\n",
    "    print(season_stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Travel Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'travel_class' in df.columns:\n",
    "    class_stats = df.groupby('travel_class')['total_fare_bdt'].agg(\n",
    "        avg_fare='mean',\n",
    "        median_fare='median',\n",
    "        booking_count='count'\n",
    "    ).sort_values('avg_fare', ascending=False)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Fare by class bar chart\n",
    "    class_colors = {'First': '#e74c3c', 'Business': '#9b59b6',\n",
    "                    'Economy': '#3498db', 'Premium Economy': '#2ecc71'}\n",
    "    bar_colors = [class_colors.get(c, '#95a5a6') for c in class_stats.index]\n",
    "\n",
    "    axes[0].bar(class_stats.index, class_stats['avg_fare'],\n",
    "               color=bar_colors, alpha=0.85, edgecolor='white')\n",
    "    axes[0].set_title('Average Fare by Travel Class', fontweight='bold')\n",
    "    axes[0].set_ylabel('Average Fare (BDT)')\n",
    "    axes[0].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "    for i, (idx, row) in enumerate(class_stats.iterrows()):\n",
    "        axes[0].text(i, row['avg_fare'] + 200, f\"{row['avg_fare']:,.0f}\",\n",
    "                    ha='center', fontsize=10)\n",
    "\n",
    "    # Distribution boxplot\n",
    "    sns.boxplot(data=df, x='travel_class', y='total_fare_bdt',\n",
    "               order=class_stats.index, ax=axes[1],\n",
    "               palette=list(class_colors.values()), fliersize=2)\n",
    "    axes[1].set_title('Fare Spread by Travel Class', fontweight='bold')\n",
    "    axes[1].set_ylabel('Total Fare (BDT)')\n",
    "    axes[1].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "\n",
    "    plt.suptitle('Travel Class Analysis', fontsize=15, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('class_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print('\\nğŸ’º Class Stats:')\n",
    "    print(class_stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix using encoded features\n",
    "corr_cols = encoded_features + ['total_fare_bdt']\n",
    "corr_cols = [c for c in corr_cols if c in df_model.columns]\n",
    "\n",
    "corr_matrix = df_model[corr_cols].corr()\n",
    "\n",
    "# Rename for readability\n",
    "clean_names = {c: c.replace('_encoded', '').replace('_', ' ').title() for c in corr_cols}\n",
    "corr_matrix.rename(columns=clean_names, index=clean_names, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(\n",
    "    corr_matrix, mask=mask, annot=True, fmt='.2f',\n",
    "    cmap='RdYlGn', center=0, linewidths=0.5,\n",
    "    annot_kws={'size': 10}\n",
    ")\n",
    "plt.title('Feature Correlation Heatmap', fontsize=15, fontweight='bold', pad=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Top correlations with target\n",
    "target_corr = corr_matrix['Total Fare Bdt'].drop('Total Fare Bdt').sort_values(key=abs, ascending=False)\n",
    "print('\\nğŸ”— Correlation with Total Fare (strongest to weakest):')\n",
    "print(target_corr.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Peak vs Off-Peak Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'is_peak_season' in df.columns:\n",
    "    peak_labels = {0: 'Off-Peak', 1: 'Peak Season'}\n",
    "    df['peak_label'] = df['is_peak_season'].map(peak_labels)\n",
    "\n",
    "    peak_stats = df.groupby('peak_label')['total_fare_bdt'].agg(['mean', 'median', 'count'])\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Bar comparison\n",
    "    p_colors = ['#3498db', '#e74c3c']\n",
    "    axes[0].bar(peak_stats.index, peak_stats['mean'], color=p_colors, alpha=0.85, edgecolor='white')\n",
    "    axes[0].set_title('Average Fare: Peak vs Off-Peak', fontweight='bold')\n",
    "    axes[0].set_ylabel('Average Fare (BDT)')\n",
    "    axes[0].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "    for i, (idx, row) in enumerate(peak_stats.iterrows()):\n",
    "        axes[0].text(i, row['mean'] + 200, f\"{row['mean']:,.0f}\",\n",
    "                    ha='center', fontweight='bold', fontsize=11)\n",
    "\n",
    "    # Premium calculation\n",
    "    if 'airline' in df.columns:\n",
    "        peak_by_airline = df.groupby(['airline', 'peak_label'])['total_fare_bdt'].mean().unstack()\n",
    "        if 'Peak Season' in peak_by_airline.columns and 'Off-Peak' in peak_by_airline.columns:\n",
    "            peak_by_airline['premium_pct'] = (\n",
    "                (peak_by_airline['Peak Season'] - peak_by_airline['Off-Peak'])\n",
    "                / peak_by_airline['Off-Peak'] * 100\n",
    "            )\n",
    "            peak_by_airline_sorted = peak_by_airline.sort_values('premium_pct', ascending=False)\n",
    "\n",
    "            colors_prem = ['#e74c3c' if v > 0 else '#2ecc71'\n",
    "                          for v in peak_by_airline_sorted['premium_pct']]\n",
    "            axes[1].barh(peak_by_airline_sorted.index,\n",
    "                        peak_by_airline_sorted['premium_pct'],\n",
    "                        color=colors_prem, alpha=0.85, edgecolor='white')\n",
    "            axes[1].axvline(0, color='black', linewidth=0.8)\n",
    "            axes[1].set_title('Peak Season Premium by Airline (%)', fontweight='bold')\n",
    "            axes[1].set_xlabel('Price Premium (%)')\n",
    "\n",
    "    plt.suptitle('Peak vs Off-Peak Season Analysis', fontsize=15, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('peak_season_analysis.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    peak_off = peak_stats.loc['Off-Peak', 'mean'] if 'Off-Peak' in peak_stats.index else 0\n",
    "    peak_on = peak_stats.loc['Peak Season', 'mean'] if 'Peak Season' in peak_stats.index else 0\n",
    "    if peak_off > 0:\n",
    "        premium = (peak_on - peak_off) / peak_off * 100\n",
    "        print(f'\\nğŸ’° Peak Season Premium: +{premium:.1f}% over off-peak')\n",
    "    print('\\nğŸ“… Peak vs Off-Peak Summary:')\n",
    "    print(peak_stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Baseline Model â€” Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_tr, y_tr, X_te, y_te, scaled=False, scaler=None):\n",
    "    \"\"\"Fit model, evaluate, and return metrics dict\"\"\"\n",
    "    X_train_use = scaler.transform(X_tr) if scaled and scaler else X_tr\n",
    "    X_test_use  = scaler.transform(X_te) if scaled and scaler else X_te\n",
    "\n",
    "    model.fit(X_train_use, y_tr)\n",
    "    train_pred = model.predict(X_train_use)\n",
    "    test_pred  = model.predict(X_test_use)\n",
    "\n",
    "    # Cross-val on training set\n",
    "    cv_scores = cross_val_score(model, X_train_use, y_tr,\n",
    "                                cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "    metrics = {\n",
    "        'Model': name,\n",
    "        'Train RÂ²': round(r2_score(y_tr, train_pred), 4),\n",
    "        'Test RÂ²': round(r2_score(y_te, test_pred), 4),\n",
    "        'CV RÂ² Mean': round(cv_scores.mean(), 4),\n",
    "        'CV RÂ² Std': round(cv_scores.std(), 4),\n",
    "        'Test MAE': round(mean_absolute_error(y_te, test_pred), 2),\n",
    "        'Test RMSE': round(np.sqrt(mean_squared_error(y_te, test_pred)), 2),\n",
    "        'predictions': test_pred\n",
    "    }\n",
    "\n",
    "    print(f\"{'=' * 50}\")\n",
    "    print(f\"ğŸ“Š {name}\")\n",
    "    print(f\"   Train RÂ²:   {metrics['Train RÂ²']:.4f}\")\n",
    "    print(f\"   Test RÂ²:    {metrics['Test RÂ²']:.4f}\")\n",
    "    print(f\"   CV RÂ² Mean: {metrics['CV RÂ² Mean']:.4f} Â± {metrics['CV RÂ² Std']:.4f}\")\n",
    "    print(f\"   Test MAE:   {metrics['Test MAE']:,.2f} BDT\")\n",
    "    print(f\"   Test RMSE:  {metrics['Test RMSE']:,.2f} BDT\")\n",
    "\n",
    "    return metrics, model\n",
    "\n",
    "all_results = []\n",
    "trained_models = {}\n",
    "\n",
    "# Baseline: Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr_metrics, lr_model = evaluate_model(\n",
    "    'Linear Regression', lr, X_train, y_train, X_test, y_test,\n",
    "    scaled=True, scaler=scaler\n",
    ")\n",
    "all_results.append(lr_metrics)\n",
    "trained_models['Linear Regression'] = lr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis for linear regression\n",
    "lr_preds = lr_model.predict(X_test_scaled)\n",
    "residuals = y_test - lr_preds\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Predicted vs Actual\n",
    "axes[0].scatter(y_test, lr_preds, alpha=0.3, s=8, color='steelblue')\n",
    "lims = [min(y_test.min(), lr_preds.min()), max(y_test.max(), lr_preds.max())]\n",
    "axes[0].plot(lims, lims, 'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Fare (BDT)')\n",
    "axes[0].set_ylabel('Predicted Fare (BDT)')\n",
    "axes[0].set_title('Predicted vs Actual â€” Linear Regression', fontweight='bold')\n",
    "axes[0].legend()\n",
    "\n",
    "# Residual distribution\n",
    "axes[1].hist(residuals, bins=50, color='coral', alpha=0.7, edgecolor='white')\n",
    "axes[1].axvline(0, color='black', linestyle='--', linewidth=2)\n",
    "axes[1].set_xlabel('Residual (Actual - Predicted)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Residual Distribution â€” Linear Regression', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('linear_regression_residuals.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Advanced Models\n",
    "### 7.1 Ridge Regression (Regularisation â€” L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search for best alpha\n",
    "ridge_params = {'alpha': [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "ridge_cv = GridSearchCV(Ridge(), ridge_params, cv=5, scoring='r2', n_jobs=-1)\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "best_alpha_ridge = ridge_cv.best_params_['alpha']\n",
    "print(f'Best Ridge alpha: {best_alpha_ridge}')\n",
    "\n",
    "ridge_metrics, ridge_model = evaluate_model(\n",
    "    f'Ridge (Î±={best_alpha_ridge})', Ridge(alpha=best_alpha_ridge),\n",
    "    X_train, y_train, X_test, y_test, scaled=True, scaler=scaler\n",
    ")\n",
    "all_results.append(ridge_metrics)\n",
    "trained_models['Ridge'] = ridge_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Lasso Regression (Regularisation â€” L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_params = {'alpha': [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "lasso_cv = GridSearchCV(Lasso(max_iter=10000), lasso_params, cv=5, scoring='r2', n_jobs=-1)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "best_alpha_lasso = lasso_cv.best_params_['alpha']\n",
    "print(f'Best Lasso alpha: {best_alpha_lasso}')\n",
    "\n",
    "lasso_metrics, lasso_model = evaluate_model(\n",
    "    f'Lasso (Î±={best_alpha_lasso})', Lasso(alpha=best_alpha_lasso, max_iter=10000),\n",
    "    X_train, y_train, X_test, y_test, scaled=True, scaler=scaler\n",
    ")\n",
    "all_results.append(lasso_metrics)\n",
    "trained_models['Lasso'] = lasso_model\n",
    "\n",
    "# Lasso feature selection (zeros out weak features)\n",
    "lasso_coefs = pd.Series(lasso_model.coef_, index=encoded_features)\n",
    "n_zero = (lasso_coefs == 0).sum()\n",
    "print(f'\\nğŸ” Lasso zeroed out {n_zero} of {len(lasso_coefs)} features')\n",
    "print('Non-zero Lasso coefficients:')\n",
    "print(lasso_coefs[lasso_coefs != 0].sort_values(key=abs, ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Regularisation Comparison (Ridge vs Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "ridge_r2, lasso_r2 = [], []\n",
    "\n",
    "for a in alphas:\n",
    "    r = Ridge(alpha=a).fit(X_train_scaled, y_train)\n",
    "    l = Lasso(alpha=a, max_iter=10000).fit(X_train_scaled, y_train)\n",
    "    ridge_r2.append(r2_score(y_test, r.predict(X_test_scaled)))\n",
    "    lasso_r2.append(r2_score(y_test, l.predict(X_test_scaled)))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.semilogx(alphas, ridge_r2, 'b-o', label='Ridge (L2)', linewidth=2)\n",
    "plt.semilogx(alphas, lasso_r2, 'r-s', label='Lasso (L1)', linewidth=2)\n",
    "plt.axvline(best_alpha_ridge, color='blue', linestyle=':', alpha=0.7, label=f'Best Ridge Î±={best_alpha_ridge}')\n",
    "plt.axvline(best_alpha_lasso, color='red', linestyle=':', alpha=0.7, label=f'Best Lasso Î±={best_alpha_lasso}')\n",
    "plt.xlabel('Alpha (Regularisation Strength)')\n",
    "plt.ylabel('Test RÂ²')\n",
    "plt.title('Ridge vs Lasso: Effect of Regularisation Strength', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('regularisation_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = {'max_depth': [3, 5, 8, 10, 15, None],\n",
    "             'min_samples_split': [2, 5, 10]}\n",
    "dt_cv = GridSearchCV(DecisionTreeRegressor(random_state=RANDOM_STATE),\n",
    "                     dt_params, cv=5, scoring='r2', n_jobs=-1)\n",
    "dt_cv.fit(X_train, y_train)\n",
    "best_dt_params = dt_cv.best_params_\n",
    "print(f'Best Decision Tree params: {best_dt_params}')\n",
    "\n",
    "dt_metrics, dt_model = evaluate_model(\n",
    "    'Decision Tree', DecisionTreeRegressor(random_state=RANDOM_STATE, **best_dt_params),\n",
    "    X_train, y_train, X_test, y_test\n",
    ")\n",
    "all_results.append(dt_metrics)\n",
    "trained_models['Decision Tree'] = dt_model\n",
    "\n",
    "# Bias-variance check\n",
    "depths = list(range(1, 15))\n",
    "train_scores, test_scores = [], []\n",
    "for d in depths:\n",
    "    dt = DecisionTreeRegressor(max_depth=d, random_state=RANDOM_STATE)\n",
    "    dt.fit(X_train, y_train)\n",
    "    train_scores.append(r2_score(y_train, dt.predict(X_train)))\n",
    "    test_scores.append(r2_score(y_test, dt.predict(X_test)))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(depths, train_scores, 'b-o', label='Train RÂ²', linewidth=2)\n",
    "plt.plot(depths, test_scores, 'r-s', label='Test RÂ²', linewidth=2)\n",
    "plt.axvline(best_dt_params.get('max_depth', max(depths)),\n",
    "            color='green', linestyle='--', label='Best Depth')\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('RÂ²')\n",
    "plt.title('Decision Tree: Bias-Variance Tradeoff', fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('bias_variance_tradeoff.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200, max_depth=15,\n",
    "    min_samples_split=5, n_jobs=-1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "rf_metrics, rf_model = evaluate_model(\n",
    "    'Random Forest', rf,\n",
    "    X_train, y_train, X_test, y_test\n",
    ")\n",
    "all_results.append(rf_metrics)\n",
    "trained_models['Random Forest'] = rf_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Gradient Boosting â­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    min_samples_split=5,\n",
    "    subsample=0.8,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "gb_metrics, gb_model = evaluate_model(\n",
    "    'Gradient Boosting', gb,\n",
    "    X_train, y_train, X_test, y_test\n",
    ")\n",
    "all_results.append(gb_metrics)\n",
    "trained_models['Gradient Boosting'] = gb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([\n",
    "    {k: v for k, v in r.items() if k != 'predictions'}\n",
    "    for r in all_results\n",
    "]).set_index('Model')\n",
    "\n",
    "print('=' * 75)\n",
    "print('                    MODEL COMPARISON TABLE')\n",
    "print('=' * 75)\n",
    "print(results_df.to_string())\n",
    "print('=' * 75)\n",
    "\n",
    "best_model_name = results_df['Test RÂ²'].idxmax()\n",
    "best_r2 = results_df.loc[best_model_name, 'Test RÂ²']\n",
    "best_mae = results_df.loc[best_model_name, 'Test MAE']\n",
    "print(f'\\nğŸ† Best Model: {best_model_name}')\n",
    "print(f'   Test RÂ²:  {best_r2:.4f}')\n",
    "print(f'   Test MAE: {best_mae:,.2f} BDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "models_order = results_df.sort_values('Test RÂ²', ascending=True).index\n",
    "colors_bar = ['#e74c3c' if m == best_model_name else '#3498db' for m in models_order]\n",
    "\n",
    "# RÂ² comparison\n",
    "axes[0].barh(models_order, results_df.loc[models_order, 'Test RÂ²'],\n",
    "             color=colors_bar, alpha=0.85, edgecolor='white')\n",
    "axes[0].set_xlabel('Test RÂ²')\n",
    "axes[0].set_title('Test RÂ² Comparison', fontweight='bold')\n",
    "axes[0].axvline(0.5, color='gray', linestyle=':', alpha=0.7, label='0.5 baseline')\n",
    "axes[0].legend()\n",
    "for i, m in enumerate(models_order):\n",
    "    v = results_df.loc[m, 'Test RÂ²']\n",
    "    axes[0].text(v + 0.002, i, f'{v:.4f}', va='center', fontsize=9)\n",
    "\n",
    "# MAE comparison\n",
    "axes[1].barh(models_order, results_df.loc[models_order, 'Test MAE'],\n",
    "             color=colors_bar, alpha=0.85, edgecolor='white')\n",
    "axes[1].set_xlabel('Test MAE (BDT)')\n",
    "axes[1].set_title('Test MAE Comparison (lower = better)', fontweight='bold')\n",
    "axes[1].xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "\n",
    "# Train vs Test RÂ² (overfitting check)\n",
    "x = np.arange(len(results_df))\n",
    "w = 0.35\n",
    "axes[2].bar(x - w/2, results_df['Train RÂ²'], w, label='Train RÂ²',\n",
    "           color='steelblue', alpha=0.8, edgecolor='white')\n",
    "axes[2].bar(x + w/2, results_df['Test RÂ²'], w, label='Test RÂ²',\n",
    "           color='coral', alpha=0.8, edgecolor='white')\n",
    "axes[2].set_xticks(x)\n",
    "axes[2].set_xticklabels(\n",
    "    [m.replace(' ', '\\n') for m in results_df.index],\n",
    "    rotation=0, ha='center', fontsize=9\n",
    ")\n",
    "axes[2].set_ylabel('RÂ² Score')\n",
    "axes[2].set_title('Train vs Test RÂ² (Overfitting Check)', fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle('Model Performance Comparison', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs Actual for best two models\n",
    "top_2 = results_df.sort_values('Test RÂ²', ascending=False).head(2).index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(top_2), figsize=(7 * len(top_2), 6))\n",
    "if len(top_2) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, name in zip(axes, top_2):\n",
    "    preds = next(r['predictions'] for r in all_results if r['Model'].startswith(name.split('(')[0].strip()))\n",
    "    ax.scatter(y_test, preds, alpha=0.3, s=8, color='steelblue')\n",
    "    lims = [min(y_test.min(), preds.min()), max(y_test.max(), preds.max())]\n",
    "    ax.plot(lims, lims, 'r--', linewidth=2, label='Perfect')\n",
    "    r2 = results_df.loc[name, 'Test RÂ²']\n",
    "    mae = results_df.loc[name, 'Test MAE']\n",
    "    ax.set_title(f'{name}\\nRÂ²={r2:.4f}, MAE={mae:,.0f} BDT', fontweight='bold')\n",
    "    ax.set_xlabel('Actual Fare (BDT)')\n",
    "    ax.set_ylabel('Predicted Fare (BDT)')\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('Predicted vs Actual â€” Top Models', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('predicted_vs_actual.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Model Interpretation\n",
    "### 9.1 Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "clean_feature_names = [f.replace('_encoded', '').replace('_', ' ').title() for f in encoded_features]\n",
    "\n",
    "# Random Forest feature importance\n",
    "rf_importances = pd.Series(rf_model.feature_importances_, index=clean_feature_names).sort_values(ascending=True)\n",
    "colors_fi = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(rf_importances)))\n",
    "axes[0].barh(rf_importances.index, rf_importances.values, color=colors_fi, alpha=0.85, edgecolor='white')\n",
    "axes[0].set_title('Random Forest â€” Feature Importance', fontweight='bold')\n",
    "axes[0].set_xlabel('Importance Score')\n",
    "\n",
    "# Gradient Boosting feature importance\n",
    "gb_importances = pd.Series(gb_model.feature_importances_, index=clean_feature_names).sort_values(ascending=True)\n",
    "axes[1].barh(gb_importances.index, gb_importances.values, color=colors_fi, alpha=0.85, edgecolor='white')\n",
    "axes[1].set_title('Gradient Boosting â€” Feature Importance', fontweight='bold')\n",
    "axes[1].set_xlabel('Importance Score')\n",
    "\n",
    "plt.suptitle('Feature Importance: Tree-Based Models', fontsize=15, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nğŸ” Random Forest Top Features:')\n",
    "print(rf_importances.sort_values(ascending=False).head(5).to_string())\n",
    "print('\\nğŸ” Gradient Boost Top Features:')\n",
    "print(gb_importances.sort_values(ascending=False).head(5).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model coefficients\n",
    "lr_coefs = pd.Series(\n",
    "    np.abs(lr_model.coef_), index=clean_feature_names\n",
    ").sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors_lr = plt.cm.Blues(np.linspace(0.3, 0.9, len(lr_coefs)))\n",
    "plt.barh(lr_coefs.index, lr_coefs.values, color=colors_lr, alpha=0.85, edgecolor='white')\n",
    "plt.title('Linear Regression â€” Absolute Coefficients\\n(Feature Influence on Fare)', fontweight='bold')\n",
    "plt.xlabel('Absolute Coefficient Value')\n",
    "plt.tight_layout()\n",
    "plt.savefig('linear_coefficients.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Insights & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘        BANGLADESH FLIGHT FARE â€” INSIGHTS & RECOMMENDATIONS          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\"\"\")\n",
    "\n",
    "# Compute insights dynamically\n",
    "if 'airline' in df.columns:\n",
    "    top_airline = df.groupby('airline')['total_fare_bdt'].mean().idxmax()\n",
    "    low_airline = df.groupby('airline')['total_fare_bdt'].mean().idxmin()\n",
    "    top_price   = df.groupby('airline')['total_fare_bdt'].mean().max()\n",
    "    low_price   = df.groupby('airline')['total_fare_bdt'].mean().min()\n",
    "    print(f\"\"\"\n",
    "1ï¸âƒ£  AIRLINE PRICING\n",
    "   â–¸ Most Expensive:  {top_airline} (~{top_price:,.0f} BDT average)\n",
    "   â–¸ Most Affordable: {low_airline} (~{low_price:,.0f} BDT average)\n",
    "   â–¸ Recommendation: Budget travellers should book {low_airline} routes.\n",
    "     Premium travellers seeking consistent service may prefer {top_airline}.\"\"\")\n",
    "\n",
    "if 'route' in df.columns:\n",
    "    exp_route = df.groupby('route')['total_fare_bdt'].mean().idxmax()\n",
    "    pop_route = df.groupby('route')['total_fare_bdt'].count().idxmax()\n",
    "    print(f\"\"\"\n",
    "2ï¸âƒ£  ROUTE ANALYSIS\n",
    "   â–¸ Most Expensive Route:  {exp_route}\n",
    "   â–¸ Most Popular Route:    {pop_route}\n",
    "   â–¸ Recommendation: Airlines should focus capacity on {pop_route}.\n",
    "     Travellers on expensive international routes should book far in advance.\"\"\")\n",
    "\n",
    "if 'is_peak_season' in df.columns:\n",
    "    peak_mean = df[df['is_peak_season'] == 1]['total_fare_bdt'].mean()\n",
    "    off_mean  = df[df['is_peak_season'] == 0]['total_fare_bdt'].mean()\n",
    "    if off_mean > 0:\n",
    "        premium_pct = (peak_mean - off_mean) / off_mean * 100\n",
    "        print(f\"\"\"\n",
    "3ï¸âƒ£  SEASONAL PRICING\n",
    "   â–¸ Peak Season Avg:    {peak_mean:,.0f} BDT\n",
    "   â–¸ Off-Peak Avg:       {off_mean:,.0f} BDT\n",
    "   â–¸ Peak Premium:       +{premium_pct:.1f}%\n",
    "   â–¸ Recommendation: Book at least 6-8 weeks before Eid/holidays to\n",
    "     avoid the {premium_pct:.0f}% surge. Off-peak savings average {off_mean:,.0f} BDT.\"\"\")\n",
    "\n",
    "if 'travel_class' in df.columns:\n",
    "    class_means = df.groupby('travel_class')['total_fare_bdt'].mean().sort_values(ascending=False)\n",
    "    print(f\"\"\"\n",
    "4ï¸âƒ£  TRAVEL CLASS\n",
    "   â–¸ Class pricing: {dict(class_means.apply(lambda x: f'{x:,.0f} BDT'))}\n",
    "   â–¸ Recommendation: Economy class offers the best value for domestic routes.\n",
    "     Business class is worth considering for routes >2hrs for comfort.\"\"\")\n",
    "\n",
    "# Top features\n",
    "top_feat = rf_importances.sort_values(ascending=False).index[0]\n",
    "print(f\"\"\"\n",
    "5ï¸âƒ£  ML MODEL INSIGHTS\n",
    "   â–¸ Best Model:       {best_model_name} (RÂ² = {best_r2:.4f})\n",
    "   â–¸ Average Error:    Â±{best_mae:,.0f} BDT (~${best_mae/120:.0f} USD)\n",
    "   â–¸ Top Predictor:    {top_feat}\n",
    "   â–¸ The model explains {best_r2*100:.1f}% of fare variance, suggesting the\n",
    "     remaining {(1-best_r2)*100:.1f}% is driven by factors not in the dataset\n",
    "     (booking timing, availability, promotions).\n",
    "\n",
    "6ï¸âƒ£  BUSINESS RECOMMENDATIONS\n",
    "   â–¸ Pricing Strategy: Use the ML model to automate dynamic pricing\n",
    "     recommendations for peak season routes.\n",
    "   â–¸ Capacity Planning: Allocate more aircraft to the most popular routes\n",
    "     during peak seasons.\n",
    "   â–¸ Customer Guidance: Build a fare alert tool (like this Streamlit app!)\n",
    "     to help travellers book at optimal times.\n",
    "   â–¸ Data Enhancement: Collect booking lead time, departure time, and seat\n",
    "     availability to potentially improve model accuracy beyond 66%.\n",
    "\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘  Model Performance Summary                                          â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\"\"\")\n",
    "\n",
    "for _, row in results_df.sort_values('Test RÂ²', ascending=False).iterrows():\n",
    "    star = ' â­ BEST' if row.name == best_model_name else ''\n",
    "    print(f\"â•‘  {row.name:<25} RÂ²={row['Test RÂ²']:.4f}  MAE={row['Test MAE']:>10,.0f} BDT{star}\")\n",
    "print(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary visualisation\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Panel 1: Model Comparison\n",
    "results_sorted = results_df.sort_values('Test RÂ²', ascending=False)\n",
    "bar_colors_f = ['#e74c3c' if i == 0 else '#3498db'\n",
    "                for i in range(len(results_sorted))]\n",
    "axes[0, 0].bar(results_sorted.index, results_sorted['Test RÂ²'],\n",
    "               color=bar_colors_f, alpha=0.85, edgecolor='white')\n",
    "axes[0, 0].set_title('Model RÂ² Comparison', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Test RÂ²')\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "axes[0, 0].tick_params(axis='x', rotation=30)\n",
    "for i, (idx, row) in enumerate(results_sorted.iterrows()):\n",
    "    axes[0, 0].text(i, row['Test RÂ²'] + 0.01, f\"{row['Test RÂ²']:.3f}\", ha='center', fontsize=9)\n",
    "\n",
    "# Panel 2: Top Features (Best Model)\n",
    "best_importances = (gb_importances if best_model_name == 'Gradient Boosting'\n",
    "                    else rf_importances).sort_values(ascending=False).head(8)\n",
    "colors_bi = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(best_importances)))\n",
    "axes[0, 1].bar(best_importances.index, best_importances.values,\n",
    "               color=colors_bi[::-1], alpha=0.85, edgecolor='white')\n",
    "axes[0, 1].set_title(f'Top Features â€” {best_model_name}', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Importance')\n",
    "axes[0, 1].tick_params(axis='x', rotation=35)\n",
    "\n",
    "# Panel 3: Predicted vs Actual (Best Model)\n",
    "best_preds = next(r['predictions'] for r in all_results\n",
    "                  if r['Model'].startswith(best_model_name.split('(')[0].strip()))\n",
    "axes[1, 0].scatter(y_test, best_preds, alpha=0.3, s=6, color='steelblue')\n",
    "lims = [min(y_test.min(), best_preds.min()), max(y_test.max(), best_preds.max())]\n",
    "axes[1, 0].plot(lims, lims, 'r--', linewidth=2)\n",
    "axes[1, 0].set_title(f'Predicted vs Actual â€” {best_model_name}', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Actual Fare (BDT)')\n",
    "axes[1, 0].set_ylabel('Predicted Fare (BDT)')\n",
    "\n",
    "# Panel 4: MAE Comparison\n",
    "axes[1, 1].bar(results_sorted.index, results_sorted['Test MAE'],\n",
    "               color=bar_colors_f, alpha=0.85, edgecolor='white')\n",
    "axes[1, 1].set_title('Test MAE Comparison (lower = better)', fontweight='bold')\n",
    "axes[1, 1].set_ylabel('MAE (BDT)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=30)\n",
    "axes[1, 1].yaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:,.0f}'))\n",
    "\n",
    "plt.suptitle('Bangladesh Flight Fare Prediction â€” Final Summary',\n",
    "             fontsize=16, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('âœ… All charts saved as PNG files in current directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Step | Status |\n",
    "|------|--------|\n",
    "| Problem Definition | âœ… Supervised regression on total fare |\n",
    "| Data Cleaning | âœ… Nulls, types, invalid entries handled |\n",
    "| Feature Engineering | âœ… Route, peak flag, fare category added |\n",
    "| EDA | âœ… 7 visualisation sections |\n",
    "| Baseline Model | âœ… Linear Regression |\n",
    "| Advanced Models | âœ… Ridge, Lasso, DT, RF, Gradient Boost |\n",
    "| Regularisation | âœ… Ridge vs Lasso alpha sweep |\n",
    "| Bias-Variance | âœ… Decision Tree depth analysis |\n",
    "| Feature Importance | âœ… RF + GB importance + Linear coefficients |\n",
    "| Insights | âœ… Airline, route, seasonal, class recommendations |\n",
    "| Visualisations saved | âœ… 10 PNG files generated |\n",
    "\n",
    "**Next Steps**: The trained model is used in the Airflow pipeline for automated retraining and served via FastAPI + Streamlit for live predictions. See `README_ML_SYSTEM.md` for deployment details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
